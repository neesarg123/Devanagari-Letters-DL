{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1802af40-97e9-4e0f-91f3-7ebaf7f27c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Goal:\n",
    "`Add caliberated noise to each image class to improve robustness of final DCNN`\n",
    "\n",
    "## Methodology:\n",
    "`Use FGSM to construct noise matrices that will maximize (current model's) prediction loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d82c198-2aa5-4582-9bea-cda7dc659598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27e9b0-b464-49cd-b801-ab385dd0987e",
   "metadata": {},
   "source": [
    "## Load the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a298b9bb-9740-498c-900b-0e6b97ddc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"C:/Users/Neesarg/Projects/Python/Machine Learning/Devanagari Master/Data Augmentation/Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b601372-eaab-4d63-bd8d-a71f59203d15",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b9f367e-c26e-4ef6-b7d5-cabd7f98d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_path = \"E:/Large Datasets/Devanagari Letters/DevanagariHandwrittenCharacterDataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "968b4c88-5077-4648-b5c4-fb57adc65bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 46\n",
      "Classes:\n",
      " ['character_10_yna', 'character_11_taamatar', 'character_12_thaa', 'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha', 'character_18_da', 'character_19_dha', 'character_1_ka', 'character_20_na', 'character_21_pa', 'character_22_pha', 'character_23_ba', 'character_24_bha', 'character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw', 'character_2_kha', 'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', 'character_36_gya', 'character_3_ga', 'character_4_gha', 'character_5_kna', 'character_6_cha', 'character_7_chha', 'character_8_ja', 'character_9_jha', 'digit_0', 'digit_1', 'digit_2', 'digit_3', 'digit_4', 'digit_5', 'digit_6', 'digit_7', 'digit_8', 'digit_9']\n"
     ]
    }
   ],
   "source": [
    "class_names = [os.path.basename(gp) for gp in glob.glob(global_data_path + \"Test/*\")]\n",
    "print(\"Number of Classes:\", len(class_names))\n",
    "print(\"Classes:\\n\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f264d6f-8663-44b6-96fe-f34e53be94ea",
   "metadata": {},
   "source": [
    "## Data Augmentation Methodology\n",
    "\n",
    "1. Define function f with parameters:<br> \n",
    "    a. `file_path` to class directory<br>\n",
    "    b. `alpha` value that defines ratio of samples to apply FGSM (default value: 0.3 = 510 images)<br>\n",
    "    c. `epsilon` value that defines the degree/magnitude of noise to be added to the images (<1, default value: 0.4)<br>\n",
    "2. Randomly pick alpha * 1,700 images from the directory --> set S\n",
    "3. Apply FGSM to S\n",
    "4. Append resultant images back into the class directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "705dda39-eda2-44e3-9e42-f77c8bd2fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def perform_FGSM_aug(file_path, alpha=0.3, epsilon=0.4):\n",
    "    # step 1: randomly pick alpha * 1700 images from directory\n",
    "    all_images = glob.glob(file_path + \"*\")\n",
    "    num_imgs = int(alpha * 1700)\n",
    "    random_sample_indices = random.sample(range(1700), num_imgs)\n",
    "    random_sample_img_paths = []\n",
    "    for i in range(num_imgs):\n",
    "        random_sample_img_paths.append(all_images[random_sample_indices[i]])\n",
    "    \n",
    "    def create_adversarial_pattern(input_image, input_label):\n",
    "        \"\"\"Returns the direction in the gradient of cost function such to maximize loss\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_image)\n",
    "            prediction = model(input_image)\n",
    "            loss = loss_object(input_label, prediction)\n",
    "            \n",
    "        # Get the gradients of the loss w.r.t to the input image\n",
    "        gradient = tape.gradient(loss, input_image)\n",
    "        # Get the sign of the gradient to create the perturbation mask/noise\n",
    "        signed_grad = tf.sign(gradient)\n",
    "        return signed_grad\n",
    "    \n",
    "    resultant_imgs = []\n",
    "    # step 2: apply FGSM to the randomly sampled images\n",
    "    for img_path in random_sample_img_paths:\n",
    "        img = Image.open(img_path)\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0)  # batch axis expected to make prediction\n",
    "        predictions = model.predict(img_array)\n",
    "        scores = tf.nn.softmax(predictions[0])\n",
    "        label = tf.one_hot(np.argmax(scores), scores.shape[-1])  # one hot vec of length 46\n",
    "        label = tf.reshape(label, (1, scores.shape[-1]))\n",
    "        perturbations = create_adversarial_pattern(img_array, label)\n",
    "        adversarial_img = img_array + epsilon * perturbations\n",
    "        adversarial_img = tf.clip_by_value(adversarial_img, -1, 1)  # min max values\n",
    "        \n",
    "        resultant_imgs.append(np.squeeze(adversarial_img[0]) * 0.5 + 0.5)  # to change [-1, 1] to [0, 1]\n",
    "    \n",
    "    for ix, result_img in enumerate(resultant_imgs):\n",
    "        fig = plt.gcf()\n",
    "        plt.axis('off')\n",
    "        plt.imsave(file_path + \"fgsm_\" + str(ix) + \".png\", result_img, cmap='gray')\n",
    "        plt.close(fig)  # so image does not get displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877565e-0b24-493c-a67f-539351a49042",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in class_names:\n",
    "    perform_FGSM_aug(file_path=global_data_path + \"Train/\" + c + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f31e8-9053-4183-b7c0-348681aeb4bb",
   "metadata": {},
   "source": [
    "## At this point, each class has 510 more training images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Machine-Learning]",
   "language": "python",
   "name": "conda-env-Machine-Learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
