{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEVANAGARI FINAL.ipynb",
      "provenance": [],
      "mount_file_id": "1kvP4kk_jpIxuDjQjK1u7F2MAnYhrIOtT",
      "authorship_tag": "ABX9TyOjNYVIU71jg0ITDAeRP3HE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neesarg123/Devanagri-Letters-DL/blob/main/DEVANAGARI_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbkQGUyYMqNO"
      },
      "source": [
        "## Loading the images from the google drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDQWcMOL9Kh"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('/content/Dataset'):\n",
        "   !unzip \"/content/drive/MyDrive/Devanagari Letters/DevanagariHandwrittenCharacterDataset.zip\" -d \"/content/Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxTYh2ADMx1K"
      },
      "source": [
        "## Understanding the data and dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5m3BuZN3jwU"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "\n",
        "1.   Number of Classes: 46\n",
        "2.   Total number of images: 92,000 >>> 72, 000 images in consonant datasest and 20, 000 images in numeral dataset.\n",
        "3. Training: 78,200 images (each class has 1,700)\n",
        "4. Testing: 13,800 images (each class has 300) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvsNOZq10_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71689aa6-ba41-4e6e-e9ab-6713a798a216"
      },
      "source": [
        "# how many total classes are there\n",
        "nclasses = len(os.listdir('/content/Dataset/DevanagariHandwrittenCharacterDataset/Train'))\n",
        "\n",
        "# names of the classes\n",
        "classes = [sub_dir for sub_dir in os.listdir('/content/Dataset/DevanagariHandwrittenCharacterDataset/Train')]\n",
        "\n",
        "print(\"Number of classes:\", nclasses)\n",
        "print(\"Classes:\", classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes: 36\n",
            "Classes: ['character_18_da', 'character_15_adna', 'character_21_pa', 'character_17_tha', 'character_22_pha', 'character_34_chhya', 'character_16_tabala', 'character_14_dhaa', 'character_33_ha', 'character_4_gha', 'character_6_cha', 'character_36_gya', 'character_27_ra', 'character_12_thaa', 'character_3_ga', 'character_23_ba', 'character_1_ka', 'character_9_jha', 'character_5_kna', 'character_24_bha', 'character_31_petchiryakha', 'character_10_yna', 'character_29_waw', 'character_19_dha', 'character_26_yaw', 'character_35_tra', 'character_11_taamatar', 'character_20_na', 'character_13_daa', 'character_25_ma', 'character_28_la', 'character_32_patalosaw', 'character_2_kha', 'character_7_chha', 'character_8_ja', 'character_30_motosaw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UCcifKLhRsA"
      },
      "source": [
        "### Let's remove the digit images as they can harm feature extraction of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "089wkD3XhZT3"
      },
      "source": [
        "import shutil\n",
        "\n",
        "for rootDir, subdirs, filenames in os.walk('/content/Dataset/DevanagariHandwrittenCharacterDataset'):\n",
        "  if \"digit\" in rootDir:\n",
        "    try:\n",
        "      shutil.rmtree(rootDir)\n",
        "    except Exception as e:\n",
        "      print(\"There was an error while deleting:\", rootDir, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQCvMyUidnj"
      },
      "source": [
        "### How many images in each class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWVDxUSb5dmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab61dc6e-b272-4601-9487-fd1f298588be"
      },
      "source": [
        "# Number of images (in train of all classes)\n",
        "\n",
        "for sub_dir, c in zip(os.listdir('/content/Dataset/DevanagariHandwrittenCharacterDataset/Train'), classes):\n",
        "  print(c + \":\", len(os.listdir(f'/content/Dataset/DevanagariHandwrittenCharacterDataset/Train/{sub_dir}')))\n",
        "\n",
        "print(\"#######################################################################\")\n",
        "\n",
        "# same thing for test\n",
        "for sub_dir, c in zip(os.listdir('/content/Dataset/DevanagariHandwrittenCharacterDataset/Test'), classes):\n",
        "  print(c + \":\", len(os.listdir(f'/content/Dataset/DevanagariHandwrittenCharacterDataset/Test/{sub_dir}')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "character_18_da: 1700\n",
            "character_15_adna: 1700\n",
            "character_21_pa: 1700\n",
            "character_17_tha: 1700\n",
            "character_22_pha: 1700\n",
            "character_34_chhya: 1700\n",
            "character_16_tabala: 1700\n",
            "character_14_dhaa: 1700\n",
            "character_33_ha: 1700\n",
            "character_4_gha: 1700\n",
            "character_6_cha: 1700\n",
            "character_36_gya: 1700\n",
            "character_27_ra: 1700\n",
            "character_12_thaa: 1700\n",
            "character_3_ga: 1700\n",
            "character_23_ba: 1700\n",
            "character_1_ka: 1700\n",
            "character_9_jha: 1700\n",
            "character_5_kna: 1700\n",
            "character_24_bha: 1700\n",
            "character_31_petchiryakha: 1700\n",
            "character_10_yna: 1700\n",
            "character_29_waw: 1700\n",
            "character_19_dha: 1700\n",
            "character_26_yaw: 1700\n",
            "character_35_tra: 1700\n",
            "character_11_taamatar: 1700\n",
            "character_20_na: 1700\n",
            "character_13_daa: 1700\n",
            "character_25_ma: 1700\n",
            "character_28_la: 1700\n",
            "character_32_patalosaw: 1700\n",
            "character_2_kha: 1700\n",
            "character_7_chha: 1700\n",
            "character_8_ja: 1700\n",
            "character_30_motosaw: 1700\n",
            "#######################################################################\n",
            "character_18_da: 300\n",
            "character_15_adna: 300\n",
            "character_21_pa: 300\n",
            "character_17_tha: 300\n",
            "character_22_pha: 300\n",
            "character_34_chhya: 300\n",
            "character_16_tabala: 300\n",
            "character_14_dhaa: 300\n",
            "character_33_ha: 300\n",
            "character_4_gha: 300\n",
            "character_6_cha: 300\n",
            "character_36_gya: 300\n",
            "character_27_ra: 300\n",
            "character_12_thaa: 300\n",
            "character_3_ga: 300\n",
            "character_23_ba: 300\n",
            "character_1_ka: 300\n",
            "character_9_jha: 300\n",
            "character_5_kna: 300\n",
            "character_24_bha: 300\n",
            "character_31_petchiryakha: 300\n",
            "character_10_yna: 300\n",
            "character_29_waw: 300\n",
            "character_19_dha: 300\n",
            "character_26_yaw: 300\n",
            "character_35_tra: 300\n",
            "character_11_taamatar: 300\n",
            "character_20_na: 300\n",
            "character_13_daa: 300\n",
            "character_25_ma: 300\n",
            "character_28_la: 300\n",
            "character_32_patalosaw: 300\n",
            "character_2_kha: 300\n",
            "character_7_chha: 300\n",
            "character_8_ja: 300\n",
            "character_30_motosaw: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPkaX8Xw7aWS"
      },
      "source": [
        "### Images\n",
        "\n",
        "1. Size: 32 x 32 pixels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WNXiTfT6lrA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "6f20eb6a-7f33-4e42-d6a1-7dfa902797c4"
      },
      "source": [
        "# plotting one out to see it\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = Image.open('/content/Dataset/DevanagariHandwrittenCharacterDataset/Train/character_10_yna/10543.png')\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "print(\"Image Size:\", img.size, \"pixels\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Size: (32, 32) pixels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbGi3twllLAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fbf156-58c7-4e16-88dd-525ab6b96366"
      },
      "source": [
        "# converting from an image to a numpy array to see data type\n",
        "import numpy as np\n",
        "\n",
        "na = np.asarray(img)\n",
        "\n",
        "print(na.dtype)\n",
        "# the max element to check if the data is normalized already\n",
        "print(np.max(np.asarray(img)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uint8\n",
            "255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVkk1KDJM_C5"
      },
      "source": [
        "## Data Augementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iiFR3KNlzjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc042626-49ec-4673-c291-9435befb1a08"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,  # normalization\n",
        "                                   rotation_range=50,  # rotation\n",
        "                                   width_shift_range=0.2,  # random crop\n",
        "                                   height_shift_range=0.2,  # random crop\n",
        "                                   shear_range=0.8,  # random manipulation\n",
        "                                   zoom_range=0.2,  # zooming in \n",
        "                                   fill_mode='constant',  # to fill with constant padding \n",
        "                                   horizontal_flip=True) # mirroring\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Dataset/DevanagariHandwrittenCharacterDataset/Train',\n",
        "        target_size=(32, 32),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Dataset/DevanagariHandwrittenCharacterDataset/Test',\n",
        "        target_size=(32, 32),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 61200 images belonging to 36 classes.\n",
            "Found 10800 images belonging to 36 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfqeJMMANYsn"
      },
      "source": [
        "## Building the Model\n",
        "\n",
        "INPUT SHAPE: (32 x 32 x 1)\n",
        "\n",
        "2 CONVOLUTIONAL LAYERS\n",
        "  - C1: with kernel size of (3 x 3), filters: 64\n",
        "  - C2: with kernel size of (5 x 5), filters: 128\n",
        "  - Batch Normalization\n",
        "  - Max Pooling with kernel size of (2 x 2), stride of 2\n",
        "  - Activation function: relu\n",
        "  - C1: feature map shape (28 x 28)\n",
        "  - C2: feature map shape (10 x 10)\n",
        "  - no padding: valid\n",
        "\n",
        "Flatten \n",
        "\n",
        "FC Layer\n",
        "  - D1: 128 neurons, activation: relu (maybe can remove later)\n",
        "  - Dropout: 0.2\n",
        "  - D2/output: 36 neurons, activation: softmax\n",
        "\n",
        "Optimizer\n",
        "  - SGD with momentum of 0.9\n",
        "  - Learning rate: 0.005 (maybe can change to 0.001 later)\n",
        "\n",
        "Loss\n",
        "  - categorical cross entropy\n",
        "\n",
        "Epochs: 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RELFWURpNSNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f250ca-77e8-4abe-ebdf-6b44acc07470"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "INPUT_SHAPE = (32, 32, 1)\n",
        "\n",
        "activation = 'relu'\n",
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv2D(filters=32, kernel_size=(3, 3), activation=activation, padding='valid', input_shape=INPUT_SHAPE))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "model4.add(Conv2D(filters=64, kernel_size=(5, 5), activation=activation, padding='valid'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "model4.add(Flatten())\n",
        "\n",
        "model4.add(Dense(256, activation=activation))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(36, activation=\"softmax\"))\n",
        "\n",
        "opt = SGD(learning_rate=0.005, momentum=0.9)\n",
        "\n",
        "model4.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model4.summary()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 11, 11, 64)        51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               409856    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 36)                9252      \n",
            "=================================================================\n",
            "Total params: 471,076\n",
            "Trainable params: 470,884\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p01LjJ9xQXCC"
      },
      "source": [
        "### Saving Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwiJF-VnRgyT"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cc-cpA8RiFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df903b37-5760-4a97-eebe-f45687f8a76e"
      },
      "source": [
        "! pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCg1L42mRm0d"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnldeIfHR5RD"
      },
      "source": [
        "#### Checkpoint callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WcQb1-lQZqD"
      },
      "source": [
        "checkpoint_path = \"training/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wMXvrM9Uc3q"
      },
      "source": [
        "#### Early Stopping Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBxZul9GUhlH"
      },
      "source": [
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnuvpz63asZG"
      },
      "source": [
        "## Hypertuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nun2Xa8gT0pm"
      },
      "source": [
        "## Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96G8YjCwT2YR",
        "outputId": "b4d70a5a-3828-4661-99b6-e0af496bd570"
      },
      "source": [
        "history = model4.fit(\n",
        "        x=train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,  \n",
        "        validation_steps=validation_generator.samples // batch_size,\n",
        "        callbacks=[model_checkpoint_callback, early_stop_callback],\n",
        "        epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "306/306 [==============================] - 39s 123ms/step - loss: 3.6322 - accuracy: 0.0719 - val_loss: 4.1263 - val_accuracy: 0.0614\n",
            "Epoch 2/50\n",
            "306/306 [==============================] - 40s 130ms/step - loss: 2.8994 - accuracy: 0.1961 - val_loss: 2.7727 - val_accuracy: 0.2345\n",
            "Epoch 3/50\n",
            "306/306 [==============================] - 39s 127ms/step - loss: 2.4466 - accuracy: 0.3070 - val_loss: 2.3724 - val_accuracy: 0.3301\n",
            "Epoch 4/50\n",
            "306/306 [==============================] - 40s 131ms/step - loss: 2.0205 - accuracy: 0.4116 - val_loss: 1.6258 - val_accuracy: 0.5284\n",
            "Epoch 5/50\n",
            "306/306 [==============================] - 46s 150ms/step - loss: 1.7587 - accuracy: 0.4812 - val_loss: 1.5815 - val_accuracy: 0.5306\n",
            "Epoch 6/50\n",
            "306/306 [==============================] - 38s 124ms/step - loss: 1.5579 - accuracy: 0.5349 - val_loss: 1.5801 - val_accuracy: 0.5269\n",
            "Epoch 7/50\n",
            "306/306 [==============================] - 42s 136ms/step - loss: 1.4081 - accuracy: 0.5785 - val_loss: 1.4617 - val_accuracy: 0.5710\n",
            "Epoch 8/50\n",
            "306/306 [==============================] - 41s 133ms/step - loss: 1.3017 - accuracy: 0.6083 - val_loss: 1.1858 - val_accuracy: 0.6496\n",
            "Epoch 9/50\n",
            "306/306 [==============================] - 40s 132ms/step - loss: 1.2074 - accuracy: 0.6383 - val_loss: 1.7257 - val_accuracy: 0.5133\n",
            "Epoch 10/50\n",
            "306/306 [==============================] - 38s 123ms/step - loss: 1.1412 - accuracy: 0.6518 - val_loss: 1.2460 - val_accuracy: 0.6220\n",
            "Epoch 11/50\n",
            "306/306 [==============================] - 40s 130ms/step - loss: 1.0714 - accuracy: 0.6736 - val_loss: 0.9502 - val_accuracy: 0.7152\n",
            "Epoch 12/50\n",
            "306/306 [==============================] - 38s 124ms/step - loss: 1.0426 - accuracy: 0.6806 - val_loss: 1.0968 - val_accuracy: 0.6693\n",
            "Epoch 13/50\n",
            "306/306 [==============================] - 39s 127ms/step - loss: 0.9754 - accuracy: 0.7051 - val_loss: 0.8667 - val_accuracy: 0.7416\n",
            "Epoch 14/50\n",
            "306/306 [==============================] - 39s 128ms/step - loss: 0.9566 - accuracy: 0.7125 - val_loss: 0.9513 - val_accuracy: 0.7074\n",
            "Epoch 15/50\n",
            "306/306 [==============================] - 37s 121ms/step - loss: 0.9238 - accuracy: 0.7195 - val_loss: 0.8333 - val_accuracy: 0.7453\n",
            "Epoch 16/50\n",
            "306/306 [==============================] - 39s 128ms/step - loss: 0.8908 - accuracy: 0.7278 - val_loss: 0.7727 - val_accuracy: 0.7669\n",
            "Epoch 17/50\n",
            "306/306 [==============================] - 39s 127ms/step - loss: 0.8579 - accuracy: 0.7345 - val_loss: 0.7913 - val_accuracy: 0.7611\n",
            "Epoch 18/50\n",
            "306/306 [==============================] - 37s 121ms/step - loss: 0.8482 - accuracy: 0.7393 - val_loss: 0.7487 - val_accuracy: 0.7767\n",
            "Epoch 19/50\n",
            "306/306 [==============================] - 39s 126ms/step - loss: 0.8255 - accuracy: 0.7478 - val_loss: 0.8122 - val_accuracy: 0.7519\n",
            "Epoch 20/50\n",
            "306/306 [==============================] - 38s 124ms/step - loss: 0.8106 - accuracy: 0.7523 - val_loss: 0.6760 - val_accuracy: 0.7948\n",
            "Epoch 21/50\n",
            "306/306 [==============================] - 37s 122ms/step - loss: 0.7985 - accuracy: 0.7573 - val_loss: 0.7559 - val_accuracy: 0.7637\n",
            "Epoch 22/50\n",
            "306/306 [==============================] - 39s 129ms/step - loss: 0.7740 - accuracy: 0.7628 - val_loss: 0.6888 - val_accuracy: 0.7925\n",
            "Epoch 23/50\n",
            "306/306 [==============================] - 37s 121ms/step - loss: 0.7662 - accuracy: 0.7657 - val_loss: 0.7272 - val_accuracy: 0.7779\n",
            "Epoch 24/50\n",
            "306/306 [==============================] - 39s 129ms/step - loss: 0.7476 - accuracy: 0.7723 - val_loss: 0.6431 - val_accuracy: 0.8052\n",
            "Epoch 25/50\n",
            "306/306 [==============================] - 39s 126ms/step - loss: 0.7393 - accuracy: 0.7737 - val_loss: 0.6247 - val_accuracy: 0.8057\n",
            "Epoch 26/50\n",
            "306/306 [==============================] - 38s 123ms/step - loss: 0.7235 - accuracy: 0.7789 - val_loss: 0.6559 - val_accuracy: 0.7998\n",
            "Epoch 27/50\n",
            "306/306 [==============================] - 38s 123ms/step - loss: 0.7242 - accuracy: 0.7789 - val_loss: 0.6363 - val_accuracy: 0.8085\n",
            "Epoch 28/50\n",
            "306/306 [==============================] - 39s 128ms/step - loss: 0.6975 - accuracy: 0.7844 - val_loss: 0.6578 - val_accuracy: 0.7927\n",
            "Epoch 29/50\n",
            "306/306 [==============================] - 37s 120ms/step - loss: 0.6852 - accuracy: 0.7891 - val_loss: 0.6285 - val_accuracy: 0.8021\n",
            "Epoch 30/50\n",
            "306/306 [==============================] - 39s 129ms/step - loss: 0.6830 - accuracy: 0.7898 - val_loss: 0.6239 - val_accuracy: 0.8076\n",
            "Epoch 31/50\n",
            "306/306 [==============================] - 37s 122ms/step - loss: 0.6761 - accuracy: 0.7924 - val_loss: 0.5676 - val_accuracy: 0.8269\n",
            "Epoch 32/50\n",
            "306/306 [==============================] - 38s 125ms/step - loss: 0.6637 - accuracy: 0.7943 - val_loss: 0.5872 - val_accuracy: 0.8171\n",
            "Epoch 33/50\n",
            "306/306 [==============================] - 38s 125ms/step - loss: 0.6682 - accuracy: 0.7909 - val_loss: 0.5514 - val_accuracy: 0.8313\n",
            "Epoch 34/50\n",
            "306/306 [==============================] - 40s 129ms/step - loss: 0.6447 - accuracy: 0.8006 - val_loss: 0.6065 - val_accuracy: 0.8100\n",
            "Epoch 35/50\n",
            "306/306 [==============================] - 37s 120ms/step - loss: 0.6481 - accuracy: 0.8015 - val_loss: 0.7089 - val_accuracy: 0.7813\n",
            "Epoch 36/50\n",
            "306/306 [==============================] - 39s 128ms/step - loss: 0.6429 - accuracy: 0.8038 - val_loss: 0.6099 - val_accuracy: 0.8164\n",
            "Epoch 37/50\n",
            "306/306 [==============================] - 37s 121ms/step - loss: 0.6372 - accuracy: 0.8029 - val_loss: 0.6789 - val_accuracy: 0.7886\n",
            "Epoch 38/50\n",
            "306/306 [==============================] - 39s 128ms/step - loss: 0.6423 - accuracy: 0.8020 - val_loss: 0.4992 - val_accuracy: 0.8463\n",
            "Epoch 39/50\n",
            "306/306 [==============================] - 38s 125ms/step - loss: 0.6198 - accuracy: 0.8099 - val_loss: 0.5388 - val_accuracy: 0.8364\n",
            "Epoch 40/50\n",
            "190/306 [=================>............] - ETA: 12s - loss: 0.6247 - accuracy: 0.8075"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p15ob2V1w9jp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}